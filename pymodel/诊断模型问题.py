"""
å…¨é¢è¯Šæ–­æ¨¡å‹é—®é¢˜ - æ‰¾å‡ºæ‰€æœ‰è¯†åˆ«é”™è¯¯çš„æ¨¡å¼

åŠŸèƒ½ï¼š
1. åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹
2. ç»Ÿè®¡æ‰€æœ‰é”™è¯¯åˆ†ç±»çš„æ¨¡å¼
3. æ‰¾å‡ºæœ€å®¹æ˜“æ··æ·†çš„ç±»åˆ«å¯¹
4. åˆ†æé—®é¢˜çš„ä¸¥é‡ç¨‹åº¦
"""

import torch
import numpy as np
from collections import defaultdict
from utils.data_loader import get_data_loaders
from models.mobilenet_v2 import get_model
from utils.train_utils import test_model
from utils.misc import safe_torch_load
import config
from tqdm import tqdm


def analyze_predictions_detailed(model, test_loader):
    """è¯¦ç»†åˆ†æé¢„æµ‹ç»“æœ"""
    model.eval()
    
    # ç»Ÿè®¡å˜é‡
    correct = 0
    total = 0
    confusion_pairs = defaultdict(int)  # {(true_class, pred_class): count}
    class_correct = defaultdict(int)
    class_total = defaultdict(int)
    class_confidences = defaultdict(list)
    
    print("\næ­£åœ¨åˆ†ææµ‹è¯•é›†é¢„æµ‹ç»“æœ...")
    
    with torch.no_grad():
        for images, labels in tqdm(test_loader, desc="åˆ†æä¸­"):
            images = images.to(config.DEVICE)
            labels = labels.to(config.DEVICE)
            
            outputs = model(images)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            _, predicted = torch.max(outputs, 1)
            
            # ç»Ÿè®¡
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            # è¯¦ç»†ç»Ÿè®¡æ¯ä¸ªæ ·æœ¬
            for true_label, pred_label, probs in zip(labels.cpu().numpy(), 
                                                       predicted.cpu().numpy(), 
                                                       probabilities.cpu().numpy()):
                class_total[true_label] += 1
                confidence = probs[pred_label] * 100
                class_confidences[true_label].append(confidence)
                
                if true_label == pred_label:
                    class_correct[true_label] += 1
                else:
                    # è®°å½•æ··æ·†å¯¹
                    confusion_pairs[(true_label, pred_label)] += 1
    
    accuracy = correct / total
    
    return {
        'accuracy': accuracy,
        'confusion_pairs': confusion_pairs,
        'class_correct': class_correct,
        'class_total': class_total,
        'class_confidences': class_confidences
    }


def print_diagnosis(results):
    """æ‰“å°è¯Šæ–­æŠ¥å‘Š"""
    print("\n" + "="*80)
    print("ğŸ“Š æ¨¡å‹è¯Šæ–­æŠ¥å‘Š")
    print("="*80)
    
    # 1. æ€»ä½“å‡†ç¡®ç‡
    print(f"\nã€æ€»ä½“æ€§èƒ½ã€‘")
    print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {results['accuracy']*100:.2f}%")
    
    # 2. æœ€ä¸¥é‡çš„æ··æ·†å¯¹ï¼ˆTop 20ï¼‰
    print(f"\nã€æœ€ä¸¥é‡çš„è¯†åˆ«é”™è¯¯ã€‘ï¼ˆTop 20ï¼‰")
    print("-"*80)
    confusion_pairs = results['confusion_pairs']
    sorted_pairs = sorted(confusion_pairs.items(), key=lambda x: x[1], reverse=True)
    
    if not sorted_pairs:
        print("âœ… å¤ªå¥½äº†ï¼æµ‹è¯•é›†ä¸Šæ²¡æœ‰é”™è¯¯ï¼")
    else:
        print(f"{'åºå·':<4} {'çœŸå®ç±»åˆ«':<30} {'é”™è¯¯é¢„æµ‹ä¸º':<30} {'é”™è¯¯æ¬¡æ•°':<8}")
        print("-"*80)
        for i, ((true_idx, pred_idx), count) in enumerate(sorted_pairs[:20], 1):
            true_class = config.CLASS_NAMES[true_idx]
            pred_class = config.CLASS_NAMES[pred_idx]
            print(f"{i:<4} {true_class:<30} {pred_class:<30} {count:<8}")
    
    # 3. è¯†åˆ«æœ€å·®çš„ç±»åˆ«ï¼ˆTop 10ï¼‰
    print(f"\nã€è¯†åˆ«æœ€å·®çš„ç±»åˆ«ã€‘ï¼ˆTop 10ï¼‰")
    print("-"*80)
    class_correct = results['class_correct']
    class_total = results['class_total']
    
    class_accuracies = []
    for class_idx in range(len(config.CLASS_NAMES)):
        if class_idx in class_total and class_total[class_idx] > 0:
            acc = class_correct.get(class_idx, 0) / class_total[class_idx]
            class_accuracies.append((class_idx, acc, class_total[class_idx]))
    
    sorted_classes = sorted(class_accuracies, key=lambda x: x[1])
    
    print(f"{'åºå·':<4} {'ç±»åˆ«':<40} {'å‡†ç¡®ç‡':<12} {'æ ·æœ¬æ•°':<8}")
    print("-"*80)
    for i, (class_idx, acc, total) in enumerate(sorted_classes[:10], 1):
        class_name = config.CLASS_NAMES[class_idx]
        marker = "âš ï¸" if acc < 0.9 else ""
        print(f"{i:<4} {class_name:<40} {acc*100:>6.2f}% {marker:<5} {total:<8}")
    
    # 4. è¯†åˆ«æœ€å¥½çš„ç±»åˆ«ï¼ˆTop 5ï¼‰
    print(f"\nã€è¯†åˆ«æœ€å¥½çš„ç±»åˆ«ã€‘ï¼ˆTop 5ï¼‰")
    print("-"*80)
    print(f"{'åºå·':<4} {'ç±»åˆ«':<40} {'å‡†ç¡®ç‡':<12} {'æ ·æœ¬æ•°':<8}")
    print("-"*80)
    for i, (class_idx, acc, total) in enumerate(sorted_classes[-5:][::-1], 1):
        class_name = config.CLASS_NAMES[class_idx]
        print(f"{i:<4} {class_name:<40} {acc*100:>6.2f}% âœ…    {total:<8}")
    
    # 5. åˆ†æå…·ä½“é—®é¢˜
    print(f"\nã€é—®é¢˜åˆ†æã€‘")
    print("-"*80)
    
    # ç»Ÿè®¡æ¶‰åŠBackground_without_leavesçš„é”™è¯¯
    bg_errors = 0
    bg_as_pred = 0
    bg_as_true = 0
    
    bg_idx = None
    if "Background_without_leaves" in config.CLASS_NAMES:
        bg_idx = config.CLASS_NAMES.index("Background_without_leaves")
        
        for (true_idx, pred_idx), count in confusion_pairs.items():
            if true_idx == bg_idx:
                bg_as_true += count
            if pred_idx == bg_idx:
                bg_as_pred += count
            if true_idx == bg_idx or pred_idx == bg_idx:
                bg_errors += count
        
        print(f"âœ“ Background_without_leaves ç›¸å…³é”™è¯¯:")
        print(f"  - è¢«è¯¯è¯†åˆ«ä¸ºå…¶ä»–ç±»åˆ«: {bg_as_true} æ¬¡")
        print(f"  - å…¶ä»–ç±»åˆ«è¢«è¯¯è¯†åˆ«ä¸ºå®ƒ: {bg_as_pred} æ¬¡")
        print(f"  - æ€»å…±æ¶‰åŠé”™è¯¯: {bg_errors} æ¬¡")
        
        if bg_as_pred > 10:
            print(f"  âš ï¸ è­¦å‘Šï¼šæœ‰ {bg_as_pred} æ¬¡å°†æ¤ç‰©å¶ç‰‡è¯¯è¯†åˆ«ä¸º'æ— å¶ç‰‡'ï¼Œå»ºè®®æ’é™¤æ­¤ç±»åˆ«ï¼")
    
    # ç»Ÿè®¡åŒæ¤ç‰©ä¸åŒç—…å®³çš„æ··æ·†
    plant_confusion = defaultdict(int)
    for (true_idx, pred_idx), count in confusion_pairs.items():
        true_name = config.CLASS_NAMES[true_idx]
        pred_name = config.CLASS_NAMES[pred_idx]
        
        # æå–æ¤ç‰©åï¼ˆ___å‰çš„éƒ¨åˆ†ï¼‰
        true_plant = true_name.split('___')[0] if '___' in true_name else true_name
        pred_plant = pred_name.split('___')[0] if '___' in pred_name else pred_name
        
        if true_plant == pred_plant:
            plant_confusion[true_plant] += count
    
    if plant_confusion:
        print(f"\nâœ“ åŒä¸€æ¤ç‰©ä¸åŒç—…å®³çš„æ··æ·†:")
        sorted_plants = sorted(plant_confusion.items(), key=lambda x: x[1], reverse=True)
        for plant, count in sorted_plants[:5]:
            print(f"  - {plant}: {count} æ¬¡")
        print(f"  ğŸ’¡ è¿™æ˜¯æ­£å¸¸ç°è±¡ï¼ŒåŒç§æ¤ç‰©çš„ä¸åŒç—…å®³è§†è§‰ç›¸ä¼¼åº¦é«˜")
    
    # 6. æ€»ç»“å’Œå»ºè®®
    print(f"\nã€å»ºè®®ã€‘")
    print("-"*80)
    
    total_errors = sum(confusion_pairs.values())
    
    if results['accuracy'] >= 0.98:
        print("âœ… æ¨¡å‹æ•´ä½“è¡¨ç°ä¼˜ç§€ï¼ˆå‡†ç¡®ç‡â‰¥98%ï¼‰")
        if bg_as_pred > 5:
            print(f"âš ï¸ ä½†ä»æœ‰ {bg_as_pred} æ¬¡è¯¯åˆ¤ä¸ºBackgroundï¼Œå»ºè®®:")
            print("   1. æ’é™¤ Background_without_leaves ç±»åˆ«")
            print("   2. é‡æ–°è®­ç»ƒæ¨¡å‹")
    elif results['accuracy'] >= 0.95:
        print("âš ï¸ æ¨¡å‹è¡¨ç°è‰¯å¥½ä½†æœ‰æ”¹è¿›ç©ºé—´ï¼ˆå‡†ç¡®ç‡95%-98%ï¼‰")
        print("   å»ºè®®:")
        print("   1. æ’é™¤ Background_without_leaves ç±»åˆ«")
        print("   2. é™ä½æ•°æ®å¢å¼ºå¼ºåº¦ï¼ˆheavyâ†’mediumï¼‰")
        print("   3. å¢åŠ è®­ç»ƒè½®æ¬¡ï¼ˆ30â†’50ï¼‰")
        print("   4. è€ƒè™‘ä½¿ç”¨ TTA (Test Time Augmentation)")
    else:
        print("âŒ æ¨¡å‹è¡¨ç°ä¸ä½³ï¼ˆå‡†ç¡®ç‡<95%ï¼‰")
        print("   å¼ºçƒˆå»ºè®®:")
        print("   1. æ’é™¤ Background_without_leaves ç±»åˆ«")
        print("   2. é™ä½æ•°æ®å¢å¼ºå¼ºåº¦ï¼ˆheavyâ†’light/mediumï¼‰")
        print("   3. ä½¿ç”¨æ›´å¤šè®­ç»ƒè½®æ¬¡")
        print("   4. è€ƒè™‘è§£å†»æ›´å¤šå±‚ï¼ˆFREEZE_STRATEGY='none'ï¼‰")
        print("   5. æ£€æŸ¥æ•°æ®è´¨é‡")
    
    print("\n" + "="*80)
    print(f"æ€»è®¡å‘ç° {total_errors} ä¸ªåˆ†ç±»é”™è¯¯")
    print("="*80)


def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("ğŸ” æ¨¡å‹é—®é¢˜å…¨é¢è¯Šæ–­")
    print("="*80)
    print("\nè¿™ä¸ªè„šæœ¬ä¼šï¼š")
    print("  1. åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œæ¨¡å‹")
    print("  2. ç»Ÿè®¡æ‰€æœ‰è¯†åˆ«é”™è¯¯")
    print("  3. æ‰¾å‡ºæœ€å®¹æ˜“æ··æ·†çš„ç±»åˆ«")
    print("  4. ç»™å‡ºé’ˆå¯¹æ€§çš„æ”¹è¿›å»ºè®®")
    print("\né¢„è®¡è€—æ—¶: 1-2åˆ†é’Ÿ")
    
    # åŠ è½½ç±»åˆ«å
    import json
    import os
    json_path = os.path.join(config.SPLITS_DIR, "class_names.json")
    if os.path.isfile(json_path):
        with open(json_path, "r", encoding="utf-8") as f:
            config.CLASS_NAMES = json.load(f)
    else:
        print("âŒ æœªæ‰¾åˆ°ç±»åˆ«åç§°æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ train.py")
        return
    
    # åŠ è½½æ•°æ®
    print("\næ­£åœ¨åŠ è½½æµ‹è¯•é›†...")
    _, _, test_loader = get_data_loaders()
    print(f"âœ“ æµ‹è¯•é›†åŠ è½½å®Œæˆ: {len(test_loader.dataset)} ä¸ªæ ·æœ¬")
    
    # åŠ è½½æ¨¡å‹
    print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
    model = get_model()
    if not os.path.isfile(config.MODEL_SAVE_PATH):
        print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {config.MODEL_SAVE_PATH}")
        return
    
    state_dict = safe_torch_load(
        config.MODEL_SAVE_PATH,
        map_location=config.DEVICE,
    )
    model.load_state_dict(state_dict)
    print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # åˆ†æ
    results = analyze_predictions_detailed(model, test_loader)
    
    # æ‰“å°æŠ¥å‘Š
    print_diagnosis(results)


if __name__ == "__main__":
    main()


"""
æ—¥å¿—å·¥å…·æ¨¡å—ï¼šæä¾›ç»Ÿä¸€çš„æ—¥å¿—è®°å½•ã€æŒ‡æ ‡è¿½è¸ªå’Œå¯è§†åŒ–åŠŸèƒ½
"""
import os
import json
import logging
from datetime import datetime
from typing import Dict, Any, Optional
import config


class TrainingLogger:
    """è®­ç»ƒæ—¥å¿—è®°å½•å™¨ï¼šè®°å½•è®­ç»ƒè¿‡ç¨‹ã€ä¿å­˜æŒ‡æ ‡ã€ç”Ÿæˆæ—¥å¿—æ–‡ä»¶"""
    
    def __init__(self, log_dir: Optional[str] = None, experiment_name: Optional[str] = None):
        """
        åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
        
        Args:
            log_dir: æ—¥å¿—ä¿å­˜ç›®å½•ï¼Œé»˜è®¤ä¸º saved_models/logs
            experiment_name: å®éªŒåç§°ï¼Œé»˜è®¤ä½¿ç”¨æ—¶é—´æˆ³
        """
        # è®¾ç½®æ—¥å¿—ç›®å½•
        if log_dir is None:
            log_dir = os.path.join(os.path.dirname(config.MODEL_SAVE_PATH), "logs")
        os.makedirs(log_dir, exist_ok=True)
        self.log_dir = log_dir
        
        # è®¾ç½®å®éªŒåç§°
        if experiment_name is None:
            experiment_name = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.experiment_name = experiment_name
        
        # åˆ›å»ºå®éªŒä¸“å±ç›®å½•
        self.exp_dir = os.path.join(log_dir, experiment_name)
        os.makedirs(self.exp_dir, exist_ok=True)
        
        # è®¾ç½®æ–‡ä»¶æ—¥å¿—
        self.log_file = os.path.join(self.exp_dir, "training.log")
        self.metrics_file = os.path.join(self.exp_dir, "metrics.json")
        self.config_file = os.path.join(self.exp_dir, "config.json")
        
        # é…ç½®Python logging
        self._setup_logging()
        
        # æŒ‡æ ‡å­˜å‚¨
        self.metrics_history = {
            "train_loss": [],
            "train_acc": [],
            "val_loss": [],
            "val_acc": [],
            "learning_rates": [],
            "epochs": []
        }
        
        # ä¿å­˜é…ç½®
        self._save_config()
        
        self.info(f"æ—¥å¿—åˆå§‹åŒ–å®Œæˆï¼Œå®éªŒåç§°ï¼š{experiment_name}")
        self.info(f"æ—¥å¿—ç›®å½•ï¼š{self.exp_dir}")
    
    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        # åˆ›å»ºlogger
        self.logger = logging.getLogger(f"TrainingLogger_{self.experiment_name}")
        self.logger.setLevel(logging.INFO)
        
        # æ¸…é™¤å·²æœ‰çš„handlers
        self.logger.handlers = []
        
        # æ–‡ä»¶handler
        file_handler = logging.FileHandler(self.log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # æ§åˆ¶å°handler
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # æ ¼å¼åŒ–
        formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        # æ·»åŠ handlers
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
    
    def _save_config(self):
        """ä¿å­˜è®­ç»ƒé…ç½®"""
        config_dict = {
            "data_root": config.DATA_ROOT,
            "batch_size": config.BATCH_SIZE,
            "image_size": config.IMAGE_SIZE,
            "epochs": config.EPOCHS,
            "learning_rate": config.LEARNING_RATE,
            "weight_decay": config.WEIGHT_DECAY,
            "device": str(config.DEVICE),
            "unfreeze_last_blocks": getattr(config, "UNFREEZE_LAST_BLOCKS", 0),
            "early_stop_patience": getattr(config, "EARLY_STOP_PATIENCE", 0),
            "label_smoothing": getattr(config, "LABEL_SMOOTHING", 0.0),
            "use_amp": getattr(config, "USE_AMP", False),
            "use_balanced_sampler": getattr(config, "USE_BALANCED_SAMPLER", False),
            "train_max_per_class": getattr(config, "TRAIN_MAX_PER_CLASS", 0),
            "num_classes": len(config.CLASS_NAMES) if config.CLASS_NAMES else 0,
            "experiment_name": self.experiment_name,
            "timestamp": datetime.now().isoformat()
        }
        
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(config_dict, f, indent=2, ensure_ascii=False)
    
    def info(self, message: str):
        """è®°å½•INFOçº§åˆ«æ—¥å¿—"""
        self.logger.info(message)
    
    def warning(self, message: str):
        """è®°å½•WARNINGçº§åˆ«æ—¥å¿—"""
        self.logger.warning(message)
    
    def error(self, message: str):
        """è®°å½•ERRORçº§åˆ«æ—¥å¿—"""
        self.logger.error(message)
    
    def log_epoch(self, epoch: int, train_loss: float, train_acc: float, 
                  val_loss: float, val_acc: float, lr: float):
        """
        è®°å½•æ¯ä¸ªepochçš„æŒ‡æ ‡
        
        Args:
            epoch: å½“å‰epochç¼–å·
            train_loss: è®­ç»ƒæŸå¤±
            train_acc: è®­ç»ƒå‡†ç¡®ç‡
            val_loss: éªŒè¯æŸå¤±
            val_acc: éªŒè¯å‡†ç¡®ç‡
            lr: å½“å‰å­¦ä¹ ç‡
        """
        # æ·»åŠ åˆ°å†å²è®°å½•
        self.metrics_history["epochs"].append(epoch)
        self.metrics_history["train_loss"].append(train_loss)
        self.metrics_history["train_acc"].append(train_acc)
        self.metrics_history["val_loss"].append(val_loss)
        self.metrics_history["val_acc"].append(val_acc)
        self.metrics_history["learning_rates"].append(lr)
        
        # è®°å½•æ—¥å¿—
        self.info(f"Epoch {epoch}/{config.EPOCHS} - "
                 f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | "
                 f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f} | "
                 f"LR: {lr:.6f}")
        
        # ä¿å­˜æŒ‡æ ‡åˆ°æ–‡ä»¶
        self._save_metrics()
    
    def _save_metrics(self):
        """ä¿å­˜æŒ‡æ ‡åˆ°JSONæ–‡ä»¶"""
        with open(self.metrics_file, 'w', encoding='utf-8') as f:
            json.dump(self.metrics_history, f, indent=2, ensure_ascii=False)
    
    def log_best_model(self, epoch: int, val_acc: float):
        """è®°å½•æœ€ä½³æ¨¡å‹ä¿å­˜ä¿¡æ¯"""
        self.info(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ - Epoch {epoch}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")
    
    def log_early_stop(self, epoch: int, patience: int):
        """è®°å½•æ—©åœä¿¡æ¯"""
        self.warning(f"âš ï¸ æ—©åœè§¦å‘ - Epoch {epoch}, è¿ç»­ {patience} æ¬¡æ— æå‡")
    
    def log_training_complete(self, best_val_acc: float, total_epochs: int):
        """è®°å½•è®­ç»ƒå®Œæˆä¿¡æ¯"""
        self.info("="*60)
        self.info(f"âœ… è®­ç»ƒå®Œæˆï¼")
        self.info(f"æ€»è®­ç»ƒè½®æ¬¡: {total_epochs}")
        self.info(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")
        self.info(f"æ¨¡å‹ä¿å­˜è·¯å¾„: {config.MODEL_SAVE_PATH}")
        self.info(f"æ—¥å¿—ä¿å­˜è·¯å¾„: {self.exp_dir}")
        self.info("="*60)
    
    def log_exception(self, exception: Exception):
        """è®°å½•å¼‚å¸¸ä¿¡æ¯"""
        self.error(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {type(exception).__name__}")
        self.error(f"å¼‚å¸¸è¯¦æƒ…: {str(exception)}")
        import traceback
        self.error(f"å †æ ˆè¿½è¸ª:\n{traceback.format_exc()}")
    
    def get_metrics_history(self) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡å†å²è®°å½•"""
        return self.metrics_history.copy()
    
    def get_log_dir(self) -> str:
        """è·å–æ—¥å¿—ç›®å½•è·¯å¾„"""
        return self.exp_dir


def setup_simple_logger(name: str = "PlantDisease") -> logging.Logger:
    """
    åˆ›å»ºç®€å•çš„æ—¥å¿—è®°å½•å™¨ï¼ˆç”¨äºéè®­ç»ƒè„šæœ¬ï¼‰
    
    Args:
        name: loggeråç§°
        
    Returns:
        é…ç½®å¥½çš„loggerå®ä¾‹
    """
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    
    # æ¸…é™¤å·²æœ‰handlers
    logger.handlers = []
    
    # æ§åˆ¶å°handler
    handler = logging.StreamHandler()
    handler.setLevel(logging.INFO)
    
    # æ ¼å¼åŒ–
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    handler.setFormatter(formatter)
    
    logger.addHandler(handler)
    
    return logger

